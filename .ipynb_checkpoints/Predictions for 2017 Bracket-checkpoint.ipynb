{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import math\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import urllib\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO FIGURE OUT TOURNAMENT SEEDS AND CONFERENCE CHAMPIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xTrain = np.load('xTrain.npy')\n",
    "yTrain = np.load('yTrain.npy')\n",
    "#xTrain = xTrain[90000:]\n",
    "#yTrain = yTrain[90000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115113, 17)\n"
     ]
    }
   ],
   "source": [
    "print xTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHEN YOU'RE RUNNING THIS FORREAL, TRAIN WITH THE FULL SET AND DONT SPLIT INTO TEST AND TRAIN, AND SEE WHETHER IT IMPACTS THE RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'learning_rate': [1, .1],\n",
    "                     'n_estimators': [10, 100, 500, 1000],\n",
    "                     'max_depth': [3,5,7]}]\n",
    "#tuned_parameters = [{'learning_rate': [.1],\n",
    "#                     'n_estimators': [10],\n",
    "#                     'max_depth': [3]}]\n",
    "model = GridSearchCV(gbr, tuned_parameters)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(xTrain, yTrain)\n",
    "model.fit(X_train, Y_train)\n",
    "print(model.grid_scores_)\n",
    "#preds = model.predict(X_test)\n",
    "\n",
    "#preds[preds < .5] = 0\n",
    "#preds[preds >= .5] = 1\n",
    "#print (np.mean(preds == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
       "             max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handleDifferentCSV(df):\n",
    "    # The stats CSV is a lit different in terms of naming so below is just some data cleaning\n",
    "    df['School'] = df['School'].replace('(State)', 'St', regex=True) \n",
    "    df['School'] = df['School'].replace('Albany (NY)', 'Albany NY') \n",
    "    df['School'] = df['School'].replace('Boston University', 'Boston Univ')\n",
    "    df['School'] = df['School'].replace('Central Michigan', 'C Michigan')\n",
    "    df['School'] = df['School'].replace('(Eastern)', 'E', regex=True)\n",
    "    df['School'] = df['School'].replace('Louisiana St', 'LSU')\n",
    "    df['School'] = df['School'].replace('North Carolina St', 'NC State')\n",
    "    df['School'] = df['School'].replace('Southern California', 'USC')\n",
    "    df['School'] = df['School'].replace('University of California', 'California', regex=True) \n",
    "    df['School'] = df['School'].replace('American', 'American Univ')\n",
    "    df['School'] = df['School'].replace('Arkansas-Little Rock', 'Ark Little Rock')\n",
    "    df['School'] = df['School'].replace('Arkansas-Pine Bluff', 'Ark Pine Bluff')\n",
    "    df['School'] = df['School'].replace('Bowling Green St', 'Bowling Green')\n",
    "    df['School'] = df['School'].replace('Brigham Young', 'BYU')\n",
    "    df['School'] = df['School'].replace('Cal Poly', 'Cal Poly SLO')\n",
    "    df['School'] = df['School'].replace('Centenary (LA)', 'Centenary')\n",
    "    df['School'] = df['School'].replace('Central Connecticut St', 'Central Conn')\n",
    "    df['School'] = df['School'].replace('Charleston Southern', 'Charleston So')\n",
    "    df['School'] = df['School'].replace('Coastal Carolina', 'Coastal Car')\n",
    "    df['School'] = df['School'].replace('College of Charleston', 'Col Charleston')\n",
    "    df['School'] = df['School'].replace('Cal St Fullerton', 'CS Fullerton')\n",
    "    df['School'] = df['School'].replace('Cal St Sacramento', 'CS Sacramento')\n",
    "    df['School'] = df['School'].replace('Cal St Bakersfield', 'CS Bakersfield')\n",
    "    df['School'] = df['School'].replace('Cal St Northridge', 'CS Northridge')\n",
    "    df['School'] = df['School'].replace('East Tennessee St', 'ETSU')\n",
    "    df['School'] = df['School'].replace('Detroit Mercy', 'Detroit')\n",
    "    df['School'] = df['School'].replace('Fairleigh Dickinson', 'F Dickinson')\n",
    "    df['School'] = df['School'].replace('Florida Atlantic', 'FL Atlantic')\n",
    "    df['School'] = df['School'].replace('Florida Gulf Coast', 'FL Gulf Coast')\n",
    "    df['School'] = df['School'].replace('Florida International', 'Florida Intl')\n",
    "    df['School'] = df['School'].replace('George Washington', 'G Washington')\n",
    "    df['School'] = df['School'].replace('Georgia Southern', 'Ga Southern')\n",
    "    df['School'] = df['School'].replace('Gardner-Webb', 'Gardner Webb')\n",
    "    df['School'] = df['School'].replace('Illinois-Chicago', 'IL Chicago')\n",
    "    df['School'] = df['School'].replace('Kent St', 'Kent')\n",
    "    df['School'] = df['School'].replace('Long Island University', 'Long Island')\n",
    "    df['School'] = df['School'].replace('Loyola Marymount', 'Loy Marymount')\n",
    "    df['School'] = df['School'].replace('Loyola (MD)', 'Loyola MD')\n",
    "    df['School'] = df['School'].replace('Loyola (IL)', 'Loyola-Chicago')\n",
    "    df['School'] = df['School'].replace('Massachusetts', 'MA Lowell')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    df['School'] = df['School'].replace('Miami (FL)', 'Miami FL')\n",
    "    df['School'] = df['School'].replace('Miami (OH)', 'Miami OH')\n",
    "    df['School'] = df['School'].replace('Missouri-Kansas City', 'Missouri KC')\n",
    "    df['School'] = df['School'].replace('Monmouth', 'Monmouth NJ')\n",
    "    df['School'] = df['School'].replace('Mississippi Valley St', 'MS Valley St')\n",
    "    df['School'] = df['School'].replace('Montana St', 'MTSU')\n",
    "    df['School'] = df['School'].replace('Northern Colorado', 'N Colorado')\n",
    "    df['School'] = df['School'].replace('North Dakota St', 'N Dakota St')\n",
    "    df['School'] = df['School'].replace('Northern Illinois', 'N Illinois')\n",
    "    df['School'] = df['School'].replace('Northern Kentucky', 'N Kentucky')\n",
    "    df['School'] = df['School'].replace('North Carolina A&T', 'NC A&T')\n",
    "    df['School'] = df['School'].replace('North Carolina Central', 'NC Central')\n",
    "    df['School'] = df['School'].replace('Pennsylvania', 'Penn')\n",
    "    df['School'] = df['School'].replace('South Carolina St', 'S Carolina St')\n",
    "    df['School'] = df['School'].replace('Southern Illinois', 'S Illinois')\n",
    "    df['School'] = df['School'].replace('UC-Santa Barbara', 'Santa Barbara')\n",
    "    df['School'] = df['School'].replace('Southeastern Louisiana', 'SE Louisiana')\n",
    "    df['School'] = df['School'].replace('Southeast Missouri St', 'SE Missouri St')\n",
    "    df['School'] = df['School'].replace('Stephen F. Austin', 'SF Austin')\n",
    "    df['School'] = df['School'].replace('Southern Methodist', 'SMU')\n",
    "    df['School'] = df['School'].replace('Southern Mississippi', 'Southern Miss')\n",
    "    df['School'] = df['School'].replace('Southern', 'Southern Univ')\n",
    "    df['School'] = df['School'].replace('St. Bonaventure', 'St Bonaventure')\n",
    "    df['School'] = df['School'].replace('St. Francis (NY)', 'St Francis NY')\n",
    "    df['School'] = df['School'].replace('Saint Francis (PA)', 'St Francis PA')\n",
    "    df['School'] = df['School'].replace('St. John\\'s (NY)', 'St John\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Joseph\\'s', 'St Joseph\\'s PA')\n",
    "    df['School'] = df['School'].replace('Saint Louis', 'St Louis')\n",
    "    df['School'] = df['School'].replace('Saint Mary\\'s (CA)', 'St Mary\\'s CA')\n",
    "    df['School'] = df['School'].replace('Mount Saint Mary\\'s', 'Mt St Mary\\'s')\n",
    "    df['School'] = df['School'].replace('Saint Peter\\'s', 'St Peter\\'s')\n",
    "    df['School'] = df['School'].replace('Texas A&M-Corpus Christian', 'TAM C. Christian')\n",
    "    df['School'] = df['School'].replace('Texas Christian', 'TCU')\n",
    "    df['School'] = df['School'].replace('Tennessee-Martin', 'TN Martin')\n",
    "    df['School'] = df['School'].replace('Texas-Rio Grande Valley', 'UTRGV')\n",
    "    df['School'] = df['School'].replace('Texas Southern', 'TX Southern')\n",
    "    df['School'] = df['School'].replace('Alabama-Birmingham', 'UAB')\n",
    "    df['School'] = df['School'].replace('UC-Davis', 'UC Davis')\n",
    "    df['School'] = df['School'].replace('UC-Irvine', 'UC Irvine')\n",
    "    df['School'] = df['School'].replace('UC-Riverside', 'UC Riverside')\n",
    "    df['School'] = df['School'].replace('Central Florida', 'UCF')\n",
    "    df['School'] = df['School'].replace('Louisiana-Lafayette', 'ULL')\n",
    "    df['School'] = df['School'].replace('Louisiana-Monroe', 'ULM')\n",
    "    df['School'] = df['School'].replace('Maryland-Baltimore County', 'UMBC')\n",
    "    df['School'] = df['School'].replace('North Carolina-Asheville', 'UNC Asheville')\n",
    "    df['School'] = df['School'].replace('North Carolina-Greensboro', 'UNC Greensboro')\n",
    "    df['School'] = df['School'].replace('North Carolina-Wilmington', 'UNC Wilmington')\n",
    "    df['School'] = df['School'].replace('Nevada-Las Vegas', 'UNLV')\n",
    "    df['School'] = df['School'].replace('Texas-Arlington', 'UT Arlington')\n",
    "    df['School'] = df['School'].replace('Texas-San Antonio', 'UT San Antonio')\n",
    "    df['School'] = df['School'].replace('Texas-El Paso', 'UTEP')\n",
    "    df['School'] = df['School'].replace('Virginia Commonwealth', 'VA Commonwealth')\n",
    "    df['School'] = df['School'].replace('Western Carolina', 'W Carolina')\n",
    "    df['School'] = df['School'].replace('Western Illinois', 'W Illinois')\n",
    "    df['School'] = df['School'].replace('Western Kentucky', 'WKU')\n",
    "    df['School'] = df['School'].replace('Western Michigan', 'W Michigan')\n",
    "    df['School'] = df['School'].replace('Abilene Christian', 'Abilene Chr')\n",
    "    df['School'] = df['School'].replace('Montana State', 'Montana St')\n",
    "    df['School'] = df['School'].replace('Central Arkansas', 'Cent Arkansas')\n",
    "    df['School'] = df['School'].replace('Houston Baptist', 'Houston Bap')\n",
    "    df['School'] = df['School'].replace('South Dakota St', 'S Dakota St')\n",
    "    df['School'] = df['School'].replace('Maryland-Eastern Shore', 'MD E Shore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for handling the annoying cases of Florida and FL, as well as State and St\n",
    "def handleCases(arr):\n",
    "    indices = []\n",
    "    listLen = len(arr)\n",
    "    for i in range(listLen):\n",
    "        if (arr[i] == 'St' or arr[i] == 'FL'):\n",
    "            indices.append(i)\n",
    "    for p in indices:\n",
    "        arr[p-1] = arr[p-1] + ' ' + arr[p]\n",
    "    for i in range(len(indices)): \n",
    "        arr.remove(arr[indices[i] - i])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listACCteams = ['North Carolina','Virginia','Florida St','Louisville','Notre Dame','Syracuse','Duke','Virginia Tech','Georgia Tech','Miami','Wake Forest','Clemson','NC State','Boston College','Pittsburgh']\n",
    "listPac12teams = ['Arizona','Oregon','UCLA','California','USC','Utah','Washington St','Stanford','Arizona St','Colorado','Washington','Oregon St']\n",
    "listSECteams = ['Kentucky','South Carolina','Florida','Arkansas','Alabama','Tennessee','Mississippi St','Georgia','Ole Miss','Vanderbilt','Auburn','Texas A&M','LSU','Missouri']\n",
    "listBig10teams = ['Maryland','Wisconsin','Purdue','Northwestern','Michigan St','Indiana','Iowa','Michigan','Penn St','Nebraska','Minnesota','Illinois','Ohio St','Rutgers']\n",
    "listBig12teams = ['Kansas','Baylor','West Virginia','Iowa St','TCU','Kansas St','Texas Tech','Oklahoma St','Texas','Oklahoma']\n",
    "listBigEastteams = ['Butler','Creighton','DePaul','Georgetown','Marquette','Providence','Seton Hall','St John\\'s','Villanova','Xavier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkPower6Conference(team_id):\n",
    "    teamName = teams_pd.values[team_id-1101][1]\n",
    "    if (teamName in listACCteams or teamName in listBig10teams or teamName in listBig12teams\n",
    "       or teamName in listSECteams or teamName in listPac12teams or teamName in listBigEastteams):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conference_pd = pd.read_csv('Conference.csv')\n",
    "tourney_seeds_pd = pd.read_csv('TourneySeeds.csv')\n",
    "tourney_results_pd = pd.read_csv('TourneyResults.csv')\n",
    "NCAAChampionsList = tourney_results_pd['NCAA Champion'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkConferenceChamp(team_id, year):\n",
    "    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n",
    "    champs = year_conf_pd['Regular Season Champ'].tolist()\n",
    "    # For handling cases where there is more than one champion\n",
    "    champs_separated = [words for segments in champs for words in segments.split()]\n",
    "    name = getTeamName(team_id)\n",
    "    champs_separated = handleCases(champs_separated)\n",
    "    if (name in champs_separated):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTourneyAppearances(team_id):\n",
    "    return len(tourney_seeds_pd[tourney_seeds_pd['Team'] == team_id].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkConferenceTourneyChamp(team_id, year):\n",
    "    year_conf_pd = conference_pd[conference_pd['Year'] == year]\n",
    "    champs = year_conf_pd['Tournament Champ'].tolist()\n",
    "    name = getTeamName(team_id)\n",
    "    if (name in champs):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTeamName(team_id):\n",
    "    return teams_pd[teams_pd['Team_Id'] == team_id].values[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNumChampionships(team_id):\n",
    "    name = getTeamName(team_id)\n",
    "    return NCAAChampionsList.count(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictGame(team_1_vector, team_2_vector, home):\n",
    "    diff = [a - b for a, b in zip(team_1_vector, team_2_vector)]\n",
    "    diff.append(home)\n",
    "    return model.predict([diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teams_pd = pd.read_csv('Teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get2017TourneySeed(team_name):\n",
    "    return 1\n",
    "    #Make sure to represent 25 if team isn't in the tourney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSeasonData(team_id, year):    \n",
    "    stats_SOS_pd = pd.read_csv('MMStats/MMStats_'+str(year)+'.csv')\n",
    "    stats_SOS_pd = handleDifferentCSV(stats_SOS_pd)\n",
    "    ratings_pd = pd.read_csv('RatingStats/RatingStats_'+str(year)+'.csv')\n",
    "    ratings_pd = handleDifferentCSV(ratings_pd)\n",
    "    \n",
    "    name = getTeamName(team_id)\n",
    "    team = stats_SOS_pd[stats_SOS_pd['School'] == name]\n",
    "    team_rating = ratings_pd[ratings_pd['School'] == name]\n",
    "    if (len(team.index) == 0 or len(team_rating.index) == 0): #Can't find the team\n",
    "        total3sMade = 0\n",
    "        totalTurnovers = 0\n",
    "        totalAssists = 0\n",
    "        sos = 0\n",
    "        totalRebounds = 0\n",
    "        srs = 0\n",
    "        totalSteals = 0\n",
    "        totalPointsScored = 0\n",
    "        totalPointsAllowed = 0\n",
    "        numGames = 0\n",
    "        \n",
    "    else:\n",
    "        avgPointsScored = team_rating['Pts'].values[0]\n",
    "        avgPointsAllowed = team_rating['Opp'].values[0]\n",
    "        numWins = team_rating['W'].values[0]\n",
    "        numLosses = team_rating['L'].values[0]\n",
    "        numGames = numWins + numLosses\n",
    "        total3sMade = team['X3P'].values[0]\n",
    "        totalTurnovers = team['TOV'].values[0]\n",
    "        if (math.isnan(totalTurnovers)):\n",
    "            totalTurnovers = 0\n",
    "        totalAssists = team['AST'].values[0]\n",
    "        if (math.isnan(totalAssists)):\n",
    "            totalAssists = 0\n",
    "        sos = team['SOS'].values[0]\n",
    "        srs = team['SRS'].values[0]\n",
    "        totalRebounds = team['TRB'].values[0]\n",
    "        if (math.isnan(totalRebounds)):\n",
    "            totalRebounds = 0\n",
    "        totalSteals = team['STL'].values[0]\n",
    "        if (math.isnan(totalSteals)):\n",
    "            totalSteals = 0\n",
    "    \n",
    "    #Finding tournament seed for that year\n",
    "    tournamentSeed = get2017TourneySeed(name)\n",
    "    \n",
    "    # There are some teams who may have dropped to Division 2, so they won't have games \n",
    "    # a certain year. In this case, we don't want to divide by 0, so we'll just set the\n",
    "    # averages to 0 instead\n",
    "    if numGames == 0:\n",
    "        avgPointsScored = 0\n",
    "        avgPointsAllowed = 0\n",
    "        avg3sMade = 0\n",
    "        avgTurnovers = 0\n",
    "        avgAssists = 0\n",
    "        avgRebounds = 0\n",
    "        avgSteals = 0\n",
    "    else:\n",
    "        avg3sMade = total3sMade/numGames\n",
    "        avgTurnovers = totalTurnovers/numGames\n",
    "        avgAssists = totalAssists/numGames\n",
    "        avgRebounds = totalRebounds/numGames\n",
    "        avgSteals = totalSteals/numGames\n",
    "    return [numWins, avgPointsScored, avgPointsAllowed, checkPower6Conference(team_id), avg3sMade, avgAssists, avgTurnovers,\n",
    "           checkConferenceChamp(team_id, year), checkConferenceTourneyChamp(team_id, year), tournamentSeed,\n",
    "            sos, srs, avgRebounds, avgSteals, getTourneyAppearances(team_id), getNumChampionships(team_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 90.799999999999997, 75.0, 1, 10.09375, 21.65625, 11.46875, 0, 0, 1, 5.5199999999999996, 21.359999999999999, 39.46875, 6.21875, 24, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.53282999])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This was the national championship matchup last year\n",
    "team1_vector = getSeasonData(teams_pd[teams_pd['Team_Name'] == 'UCLA'].values[0][0], 2017)\n",
    "team2_vector = getSeasonData(teams_pd[teams_pd['Team_Name'] == 'Arizona'].values[0][0], 2017)\n",
    "print team1_vector\n",
    "predictGame(team1_vector, team2_vector, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
